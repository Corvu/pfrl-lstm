{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96593329",
   "metadata": {},
   "source": [
    "# Training RL agent with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817e080",
   "metadata": {},
   "source": [
    "## Training an agent using PPO (normal and recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470830d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pfrl\n",
    "import torch\n",
    "import torch.nn\n",
    "import gym\n",
    "import numpy\n",
    "\n",
    "import gym_minigrid\n",
    "import gym_minigrid.wrappers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9345905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space (shape): (7, 7, 3)\n",
      "action space (shape): Discrete(7)\n",
      "reward: 0\n",
      "done: False\n",
      "info: {}\n"
     ]
    }
   ],
   "source": [
    "#env = gym.make('CartPole-v0')\n",
    "env = gym.make('MiniGrid-MemoryS11-v0')\n",
    "env = gym_minigrid.wrappers.ImgObsWrapper(env) # Get rid of the 'mission' field\n",
    "#env = gym_minigrid.wrappers.FlatObsWrapper(env)\n",
    "\n",
    "print('observation space (shape):', env.observation_space.shape)\n",
    "print('action space (shape):', env.action_space)\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "action = env.action_space.sample()\n",
    "obs, r, done, info = env.step(action)\n",
    "print('reward:', r)\n",
    "print('done:', done)\n",
    "print('info:', info)\n",
    "\n",
    "# Uncomment to open a GUI window rendering the current state of the environment\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780c0e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d283b22ec8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYiklEQVR4nO3de4xc5XnH8e8zszuzu+P13jze7C5ee+21jW3ADpibSRuSlJbSCkiqtKRqhFSqREoQidSqMY3UkFZpLk1Iq1ahIg2qWyWhqCHFQrmUWInStJQYbEwwNuAri/EFHFvA2t6d3Xn7xznjDMtexjvvzJmZ8/tIozlz9syz79n1Pj7nzHmfx5xziEh8JaIegIhES0lAJOaUBERiTklAJOaUBERiTklAJOYqlgTM7EYze97M9pnZ5kp9HxEpj1XiPgEzSwIvADcALwPbgQ85557z/s1EpCyVOhK4CtjnnDvgnBsHHgRuqdD3EpEyNFUo7gAwUvT6ZeDqmTZuaWlx7e3tFRqKyPSamppobm6OehhVMzIy8ppzLjt1faWSgE2z7i3nHWb2EeAjAAsWLODWW2+t0FBEprdo0SL6+/ujHkbV3HXXXYenW1+p04GXgSVFry8CXinewDl3v3Nuo3NuY0tLS4WGISJzqVQS2A6sNLMhM0sBtwFbK/S9RKQMFTkdcM5NmNmdwA+BJPCAc253Jb6XiJSnUtcEcM59D/hepeKLiB+6Y1Ak5pQERGJOSUAk5pQERGJOSUAk5pQERGJOSUAk5pQERGJOSUAk5pQERGJOSUAk5pQERGJOSUAk5pQERGKuYlOJo3Tw4EGOHTvmJVY2m2VsbIzXX3/dS7zBwUGOHTvG+Pi4l3jLly/nwIEDXmKZGUNDQ97ipVIpent7GRkZmXvjEnR0dNDU1MTJkye9xLvsssu8lhebnJxk//795PN5L/GWLVtGNapuNWQSOHbsGLt3+6lhMjw8zOjoKEePHvUSr7W1lb1793L27Fkv8bq6urztq5nR2dnpLV4mkyGRSHiLNzAwQDqd9pakent7vcQpyOfzvPTSS96SwMDAQFWSgE4HRGJOSUAk5pQERGJOSUAk5pQERGJOSUAk5sr6iNDMDgFvAJPAhHNuo5l1A/8OLAMOAb/vnDtV3jBFpFJ8HAm8xzm3wTm3MXy9GdjmnFsJbAtfi0iNqsTpwC3AlnB5C3BrBb6HiHhSbhJwwH+Z2VNhl2GAXufcUYDweXGZ30NEKqjc24avc869YmaLgcfMbG+pb5zamlxEolHWkYBz7pXw+QTwXeAq4LiZ9QGEzydmeK9ak4vUgHknATPLmFl7YRn4TeBZghbkt4eb3Q48Uu4gRaRyyjkd6AW+a2aFON9yzv3AzLYDD5nZHcBLwAfLH6aIVMq8k4Bz7gCwfpr1J4H3lTMoEake3TEoEnNKAiIx15CVhbLZLMPDw15i9fb2MjY2RiaT8RKvu7uboaEhb+XFFi5c6G1fzcxrvHQ6TVdXl7d4XV1dNDc3k0j4+b9r0aJFXuIUJBIJ+vr6vFUWamqqzp9nQyaBsbExRkdHvcU6e/ast3jj4+OcOXOGsbExL/EmJia8jc3MvMabnJwkl8t5i9fa2srk5KTX361PzjnOnTvnLQk457zEmUtDJoHXX3/dW03ATCbjtcbgwMAAx48f91ZjcMWKFd7GZmYsX77c68+uu7vbW7xEIkE6nfYW74033vASp8A5x6lTp7wlgcnJSS9x5qJrAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxN2dlITN7APhd4IRz7pJw3Yztx83sbuAOgnbldznnfliRkc9i6dKl3lqbdXZ2ksvlGBwc9BKvt7eXdDrNxMSEl3iLFy/m6quv9hILgvqMGzdunHvDEqRSKXp6egh7U5Stvb2dZDJJd3e3l3hLlizxEqcgkUgwPDzsrSxYKpXyEmcupZQX+xfgH4F/LVpXaD/+BTPbHL7+lJmtBW4D1gH9wI/MbJVzrjp1kkL9/f309/dX81tekMWL/fZo9fVHAXDkyBF2797tJVYmk2F4eNhbvL6+PlKpFIcPH/YSr6enx0ucgnw+z8jIiLeyYNlslnQ67SXWbOZMAs65n5rZsimrbwGuD5e3AD8BPhWuf9A5NwYcNLN9BP0JH/c0XqmwfD7vrf5hIpEgl8t5i1coDOorXi6X8xKn2NjYWN0VGp3vNYGZ2o8PACNF270crnsbM/uImT1pZk+eO3dunsMQkXL5rjY83cnftOnMOXc/cD9ANputTsoTiUKS4OrZNcDFwEKC/x6fAH4BnIpsZMD8k8BxM+tzzh2d0n78ZaD4astFwCvlDFCkrqWA3wE+AHQWrV8OXAfsAf4Z2F/1kZ0339OBmdqPbwVuM7O0mQ0BK4GflzdEkTrVBNwM/BFvTQAFSYJL6J8kOFKIyJxJwMy+TXBhb7WZvRy2HP8CcIOZvQjcEL7GObcbeAh4DvgB8PFqfzIgUjNWEVwqn+2TPiNIALcR2V07pXw68KEZvjRt+3Hn3OeAz5UzKJG6Z8AmoKPE7dcSnCLsq9iIZqQ7BkUqwYA1TH+pfDoZYGnlhjMbJQGRSjDgQu7haib41CACSgIileC4sM/FxoDXKjSWOSgJiFRCHngqfC7FaeCFio1mVkoCIpXyc4KjgbluhXPA/wLHKz6iaSkJiFTKEeAB4JezbJMH/hv4z2oMaHpKAiKV4ghOCf4OeB44SzDB3gE5glOARwnuGIzw1mHfcwdEpFgeeJrg9uB1BPcCLACOAbvC54hnzigJiFTDGLAjfNQYnQ6IxJySgEjMNeTpwLlz57xVjWlubiafz3srGZVOpxkfH/dWNWb58uXe6ilCUMJrxYoVXmIlk0kymYy3GojpdJpEIuGtspDPsmwQ7O+aNWu8/W6rUVoMGjQJ7Ny5c/a6djbl2U15LjI8PMzo6ChHjx71MrYrr7yS3bt3c+bMGS/xPvaxj9HX1+clFgTFPLPZrLd4QE3Xe/RpcnKSvXv3evsPo6OjoyrFRuN3OpAENhB8fvs88Azw94Cf//zm5JyrWu04qb56/N025JHArFYSlEZdx69S4BrgEuD3iLzUk0i1xe9I4OMEf/CjwMPA9wlu3Pg1gsIOIjETvyRwKcG1gJ3Ah4E/Bg4SnCa8K8JxiUQkfqcDLnx0AX1AD9Aafm00qkGJRCd+SeBhgiqvawkqJyYIEsI5Ip3EIRKV+J0OfJPgwuA5IEtwJPAG8E/AtgjHJRKR+CWBXxKUeP6bonV3AX9GcH+3SMzELwlAcO6/vej1bkqvACPSYErpO/CAmZ0ws2eL1t1jZkfM7OnwcVPR1+42s31m9ryZ/ValBj5vKaAFqM4dmSI1b76tyQG+6pz7cvGKWmlNPqv/AK5l9oYQIjEy55GAc+6nzF4gqdj51uTOuYMErRSuKmN8/v0V8IfA56MeiEhtKOeawJ1m9kx4utAVrqv91uRPAo8RlH0SkXkngfsIptxsAI4CXwnXX1BrcufcRufcxpaWlnkOQ0TKNa+bhZxz54sjm9nXCcolQj20Jr8bWE1wxUJE5nckYGbFE9jfDxQ+Oaj91uSTwATwEvCN8BFR5xeRWjDnkUDYmvx6YJGZvQx8BrjezDYQHOofAj4KQWtyMyu0Jp+gFluTfynqAYjUlvm2Jv/GLNtH3prczDArtR1sabF8xkskEt7iSW1JJBJ1V1ikIScQDQ0N0dnZ6SXWwoULmZiYYPny5V7iZbNZMpkMExMTXuItXLiQV1991UssMyOTyfDmm296iZdMJmlpaWF01M/0zFQqhZkxNubn/u7W1lZyuZy330Umk2H16tWqMVgLDhw4MHuNwQvgu8bgxo0b2b17t7dimStXrvSaBNasWcNzzz3nJV46neaiiy5i//79XuL19PTQ1NTE8eN+mvYtXbqU1157zVuSuvjii3nhhRfI5/3cg64agyLzlEb/sC+EflbSUJqADwCLox5IHWnI0wGJr0HgJoL73I9FPJZ6oSMBaRgJgnqxC4H3oImipVISkIbRA7yT4B/1IMGNoTI3JQFpGBsIOn9D0P37PWjGeCmUBKQhNBH80Rd3mNtIcHQgs1MSkIawmuAUoFgHtVbMojYpCUjdawbeTXBBcKp3A51VHU39URKQutcBXMnbi1kYwVz2i6s+ovqiJCB17zqge4avtRBcK9ANMTNTEpC61kmQBGaak2nAZcDSag2oDikJSF0bBoaYOQkAtAGb5tgmzpQEpG4lCA7156pQmSD4lGBRxUdUn5QEpG4NEHSaL8VFBM0w5O10vUTq2oNAssRtT1VyIHVMSUDq1ghvbXIh89OQSSCVSpHJZLzESqfTTE5OeotXGFsi4edMzMxIJpNeSlqZGfl83tvYCvX2fMUrjutDYWy+4uXzeZLJUo9L5jYxMcH4+Li3eDNpyCTQ29vr7Rfb1dVFLpeju3umT6IvTE9PD8PDw+RyOS/xRkdHWbTI3yWv06dPk81mvcU7c+aM13iAt3jj4+O0tbXR1tbmJd6pU6c4cuSIt/Ji7e3ttLa2eok1m4ZMAiMjIzVbY9DMvNYYzGaztLe3e4lV4LsSci1XVvY5tomJCXbs2OGtcOmSJUuqkgRKaU2+xMx+bGZ7zGy3mX0iXN9tZo+Z2Yvhc1fRe2q7PbmInFfKMfME8KfOuTXANcDHwxbkm4FtzrmVwLbw9dT25DcCXzMzfydKIuJVKa3JjzrndoTLbwB7CD6ivQXYEm62Bbg1XK799uQict4FXT0zs2UEFZyeAHqdc0chSBT8qsBrSe3JI2tNLiJvUXISMLMFwHeATzrnXp9t02nWve3zK7UmF6kNJSUBM2smSADfdM49HK4+XuhOHD6fCNfXfntyETmvlE8HjKAB6R7n3L1FX9oK3B4u3w48UrS+ttuTi8h5pdwncB3wYeAXZvZ0uO4vgC8AD5nZHcBLwAehTtqTi8h5pbQm/xkzT8V+3wzvibw9uYiURlOJRWJOSUAk5pQERGJOSUAk5pQERGJOSUAk5pQERGJOSUAk5hqyslBHRwcDA2+buDgvXV1dtLa2eitX1t7eTl9fH2NjY17iafJV7UgkEvT39zM56ecG2ebmZi9x5tKQSWDt2rWsXbs26mHMaMWKFVEPYUYnT55k165dXmKl02kGBgY4cOCAl3jd3d00NTVx4sSJuTcuweDgIMPDw15iFRQK0/rgu0DrTBoyCcj8nTlzxtsfbSaToa2tzVu8sbEx0um01/H5TAL5fJ6DBw/OXmNwAHgvsAA4CfwPcGT6TdevX8+CBQu8jW8mSgIi1WAEU/G+BFwOpICzwNPAnxDU64qILgyKVEM3cDdBlc4mYBxIA9cCfw0sjG5oSgIi1bAUuIHgiOBvw9f3ha+vJ2itHBElAZFqSACFi/3/R1CH6/HwdSdQ+fYCM9I1AZFqGCX4w88CnwXWAx8gqL65H3g1uqEpCYhUw0GCw/8/J0gA68P15wgK9h+OaFwoCYhUxzngiwQF9+4iOCI4Dnwe+Hq4PiK6JiBSLWcJ/uifCV/vBf4BOBPZiAAlAZHqmgQKTYvzRcsR0umASDX0Ax8Nl5dHOZC3UxIQqYYFwKZwuTPCcUyjnNbk95jZETN7OnzcVPQetSYXKfYCwc1CNwA7Ih7LFKUcCRRak+8ws3bgKTN7LPzaV51zXy7eeEpr8n7gR2a2Sg1IRGpTKc1HjgKF7sNvmFmhNflMzrcmBw6aWaE1+eOzvEeksbUChQmLlZ8YeEHKaU0OcKeZPWNmD5hZV7hOrclFploLPBk+riCYQBThvQHFymlNfh+wAthAcKTwlcKm07xdrckl3nYBg1MefxDpiM4r6dOB6VqTO+eOF33968Cj4Uu1JheZaoLgDsEaNGcSmKk1uZn1hdcLAN4PPBsubwW+ZWb3ElwYrHprcufeduAhJWpvb+fSSy/1EiuVSrF48WJv8To6Okgmk2QyGS/x+vr6vMQpSCaTrFu3jnzezx1Ara3VmVpYTmvyD5nZBoJD/UOEt0LUQmvyXbt2sW/fPi+xli5dypkzZ3j1VT/TvC655BL279/P2bNnvcS74oor2LFjh5fEl0gk2LBhAyMjI3NvXIK2tjZaWlq8xRsfHyeVSnmL19rayuDgoJdYEJQXO3LkyOzlxS7A6tWraWtr8xJrNuW0Jv/eLO+JtDX52bNnOX36tJdYixYtYnR01Fu8c+fOcfr0aW9JYGxsjFOnTnmJZWaMj49729dcLnd+f33IZDKk02lv8Xz9Dgqcc5w+fdpbEvBVsHQumjsgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnNKAiIxpyQgEnMN2YZsaGiIhQsXeonV2dlJLpdj2bJlXuL19vbS2trqrfpMb28vmzZt8lJezMzo7e3l2muv9TAyaG5upquri1Qq5SXeggULSCaT9Pb2eonX09PjJU5BU1MTV199tbcag75qKc6lIZPA4cOH2bNnj5dYK1asYHR0lGPHjnmJd/nll7Nnzx5vpa02bdrE9u3bvSWBa665hu3bt3sYWfCPeNWqVezcudNLvP7+flKpFIcOHfISb926dbzjHe/wEgtgYmKCp556yluC7+vroxrl+BsyCeTzea913iYnJ73FK4zNZ7xcLucllpnhnPM2tomJCe+/C5/xfP2PXczn77ZaVbN1TUAk5pQERGKulNbkLWb2czPbFbYm/2y4vtvMHjOzF8PnrqL3qDW5SJ0o5UhgDHivc249Qd/BG83sGmAzsM05txLYFr6e2pr8RuBrZpaswNhFxIM5k4ALvBm+bA4fjqAF+ZZw/Rbg1nD5fGty59xBoNCaXERqUEnXBMwsGbYgOwE85px7Augt9CIMnxeHm6s1uUgdKSkJOOcmnXMbCDoMX2Vml8yyuVqTi9SRC/p0wDl3GvgJwbn+cTPrg6BDMcFRAqg1uUhdKeXTgayZdYbLrcBvAHsJWpDfHm52O/BIuLwVuM3M0mY2RAStyUWkdKXcMdgHbAmv8CeAh5xzj5rZ48BDZnYH8BLwQaiN1uQiUrpSWpM/A7xzmvUngffN8J5IW5OLSOl0x6BIzCkJiMSckoBIzCkJiMSckoBIzCkJiMRcQ1YWuuyyy1i1apWXWOl02mv1nra2NpYuXeq1Dl02m/USy8xoa2vzFi+RSNDS0sLg4KCXeM3NzZgZ69ev9xKvtbXVS5yC5uZmbr75Zm8VgTo6OrzEmUtDJoFMJlO1Io3z4fsfn++5F77j+d7fWpVIJOju7o56GBdMpwMiMackIBJzSgIiMackIBJzSgIiMackIBJzSgIiMackIBJzSgIiMackIBJzSgIiMackIBJzSgIiMVdOV+J7zOyImT0dPm4qeo+6EovUiVKmEhe6Er9pZs3Az8zs++HXvuqc+3LxxlO6EvcDPzKzVeo9IFKbyulKPBN1JRapI+V0JQa408yeMbMHzKwrXFdSV2IRqQ3ldCW+D1gBbACOAl8JNy+pK7Fak4vUBrvQemhm9hlgtPhagJktAx51zl1iZncDOOc+H37th8A9zrnHZ4n5KjAKvHbBe1DfFhG/fQbtd1SWOufeVkByzguDZpYFcs6500Vdib9oZn3OuaPhZu8Hng2XtwLfMrN7CS4MztmV2DmXNbMnnXMbS9+f+hfHfQbtd9TjmKqcrsT/ZmYbCA71DwEfBXUlFqk3F3w6UCm1miUrKY77DNrvqMcxVS3dMXh/1AOIQBz3GbTfNaVmjgREJBq1dCQgIhGIPAmY2Y3hHIN9ZrY56vH4FN5EdcLMni1a121mj5nZi+FzV9HX6n7OhZktMbMfm9mecK7JJ8L1jb7fM82xqf39ds5F9gCSwH5gOZACdgFroxyT5/37deBy4NmidV8CNofLm4Evhstrw/1PA0PhzyUZ9T7MY5/7gMvD5XbghXDfGn2/DVgQLjcDTwDX1MN+R30kcBWwzzl3wDk3DjxIMPegITjnfgr8csrqW4At4fIW4Nai9XU/58I5d9Q5tyNcfgPYQ3DbeKPvt3PTz7Gp+f2OOgnEcZ5BrwtvsgqfF4frG+5nEd5J+k6C/xUbfr9nmGNT8/sddRIoaZ5BTDTUz8LMFgDfAT7pnHt9tk2nWVeX++2mn2Mzk5rZ76iTwMvAkqLXFwGvRDSWajluZn0A4fOJcH3D/CzCuhPfAb7pnHs4XN3w+13gnDsN/AS4kTrY76iTwHZgpZkNmVmKoBjJ1ojHVGlbgdvD5duBR4rW32ZmaTMbooQ5F7XIzAz4BrDHOXdv0Zcafb+zZtYZLhfm2OylHva7Bq6q3kRwBXk/8Omox+N5375NMM06R5D57wB6gG3Ai+Fzd9H2nw5/Ds8Dvx31+Oe5z+8iOKx9Bng6fNwUg/2+DNgZ7vezwF+G62t+v3XHoEjMRX06ICIRUxIQiTklAZGYUxIQiTklAZGYUxIQiTklAZGYUxIQibn/By11AG6OINaMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = env.render(\"rgb_array\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75434547",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_size = env.observation_space.low.size\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622496b6",
   "metadata": {},
   "source": [
    "Create an approximator - a policy-value network (for recurrent must be a cubclass of pfrl.nn.Recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f04ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_network = torch.nn.Sequential(\n",
    "    torch.nn.Linear(obs_size, 128),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(128, 128),\n",
    "    torch.nn.Tanh(),\n",
    "    pfrl.nn.Branched(\n",
    "        torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, n_actions),\n",
    "            pfrl.policies.SoftmaxCategoricalHead()\n",
    "        ),\n",
    "        torch.nn.Linear(128, 1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd0c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_network_rec = pfrl.nn.recurrent_sequential.RecurrentSequential(\n",
    "    torch.nn.Linear(obs_size, 128),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(128, 128),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.LSTM(128, 128),\n",
    "    pfrl.nn.Branched(\n",
    "        torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(128, n_actions),\n",
    "            pfrl.policies.SoftmaxCategoricalHead()\n",
    "        ),\n",
    "        torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 128),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(128, 1)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4664ffc3",
   "metadata": {},
   "source": [
    "Create an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfe5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pv_network.parameters(), eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec99300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_rec = torch.optim.Adam(pv_network_rec.parameters(), eps=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e63eb",
   "metadata": {},
   "source": [
    "Some preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63294609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the discount factor that discounts future rewards.\n",
    "gamma = 0.99\n",
    "\n",
    "# Use epsilon-greedy for exploration\n",
    "explorer = pfrl.explorers.ConstantEpsilonGreedy(\n",
    "    epsilon=0.3, random_action_func=env.action_space.sample\n",
    ")\n",
    "\n",
    "# Observations in MiniGrid are numpy.uint8, but PyTorch only\n",
    "# accepts numpy.float32 by default, tehrefore we specify\n",
    "# a converter as a feature extractor function phi.\n",
    "phi = lambda x: x.astype(numpy.float32, copy=False)\n",
    "\n",
    "# Set the device id to use GPU. To use CPU only, set it to -1.\n",
    "gpu = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de8a62",
   "metadata": {},
   "source": [
    "Prepare PPO agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4367f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = pfrl.agents.PPO(\n",
    "    pv_network,\n",
    "    optimizer,\n",
    "    recurrent=False,\n",
    "    phi=phi,\n",
    "    gamma=gamma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c14e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rec = pfrl.agents.PPO(\n",
    "    pv_network_rec,\n",
    "    optimizer_rec,\n",
    "    recurrent=True,\n",
    "    phi=phi,\n",
    "    gamma=gamma\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3acfc68",
   "metadata": {},
   "source": [
    "Train normal agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c00903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 100 R: 0\n",
      "episode: 200 R: 0.976198347107438\n",
      "episode: 300 R: 0\n",
      "episode: 400 R: 0\n",
      "episode: 500 R: 0\n",
      "episode: 600 R: 0\n",
      "episode: 700 R: 0\n",
      "episode: 800 R: 0\n",
      "episode: 900 R: 0\n",
      "episode: 1000 R: 0.9866115702479339\n",
      "statistics: [('average_value', 0.47324914), ('average_entropy', 1.509029), ('average_value_loss', 0.09772121317684651), ('average_policy_loss', -0.018263580589555205), ('n_updates', 4800), ('explained_variance', -0.005419984917829579)]\n",
      "episode: 1100 R: 0\n",
      "episode: 1200 R: 0\n",
      "episode: 1300 R: 0.9806611570247934\n",
      "episode: 1400 R: 0.9866115702479339\n",
      "episode: 1500 R: 0.9836363636363636\n",
      "episode: 1600 R: 0.9598347107438017\n",
      "episode: 1700 R: 0\n",
      "episode: 1800 R: 0.9776859504132231\n",
      "episode: 1900 R: 0.9895867768595041\n",
      "episode: 2000 R: 0\n",
      "statistics: [('average_value', 0.42121455), ('average_entropy', 1.4223869), ('average_value_loss', 0.11399808302521705), ('average_policy_loss', -0.016287857950665056), ('n_updates', 7040), ('explained_variance', -0.028229709180787044)]\n",
      "episode: 2100 R: 0.9836363636363636\n",
      "episode: 2200 R: 0.9821487603305785\n",
      "episode: 2300 R: 0\n",
      "episode: 2400 R: 0\n",
      "episode: 2500 R: 0\n",
      "episode: 2600 R: 0.9821487603305785\n",
      "episode: 2700 R: 0\n",
      "episode: 2800 R: 0\n",
      "episode: 2900 R: 0.9821487603305785\n",
      "episode: 3000 R: 0\n",
      "statistics: [('average_value', 0.43674144), ('average_entropy', 1.2907146), ('average_value_loss', 0.11991408824920655), ('average_policy_loss', -0.013745508529245854), ('n_updates', 9280), ('explained_variance', -0.044781025986987855)]\n",
      "episode: 3100 R: 0.9925619834710744\n",
      "episode: 3200 R: 0.9895867768595041\n",
      "episode: 3300 R: 0\n",
      "episode: 3400 R: 0\n",
      "episode: 3500 R: 0\n",
      "episode: 3600 R: 0\n",
      "episode: 3700 R: 0\n",
      "episode: 3800 R: 0\n",
      "episode: 3900 R: 0.9821487603305785\n",
      "episode: 4000 R: 0.976198347107438\n",
      "statistics: [('average_value', 0.4134325), ('average_entropy', 1.1843843), ('average_value_loss', 0.11871948480606079), ('average_policy_loss', -0.009049399327486753), ('n_updates', 11200), ('explained_variance', -0.009839576688537077)]\n",
      "episode: 4100 R: 0.9821487603305785\n",
      "episode: 4200 R: 0\n",
      "episode: 4300 R: 0\n",
      "episode: 4400 R: 0\n",
      "episode: 4500 R: 0.9925619834710744\n",
      "episode: 4600 R: 0\n",
      "episode: 4700 R: 0.9836363636363636\n",
      "episode: 4800 R: 0\n",
      "episode: 4900 R: 0.9821487603305785\n",
      "episode: 5000 R: 0\n",
      "statistics: [('average_value', 0.4381123), ('average_entropy', 1.0072212), ('average_value_loss', 0.13815501652657985), ('average_policy_loss', -0.008741382341831923), ('n_updates', 13120), ('explained_variance', 0.005207260628530053)]\n",
      "episode: 5100 R: 0.9895867768595041\n",
      "episode: 5200 R: 0.9137190082644628\n",
      "episode: 5300 R: 0.9776859504132231\n",
      "episode: 5400 R: 0\n",
      "episode: 5500 R: 0\n",
      "episode: 5600 R: 0.9895867768595041\n",
      "episode: 5700 R: 0.9821487603305785\n",
      "episode: 5800 R: 0.9821487603305785\n",
      "episode: 5900 R: 0.9836363636363636\n",
      "episode: 6000 R: 0\n",
      "statistics: [('average_value', 0.4620574), ('average_entropy', 1.0081192), ('average_value_loss', 0.12456498079001904), ('average_policy_loss', -0.01426296278834343), ('n_updates', 14720), ('explained_variance', -0.016321136750467424)]\n",
      "episode: 6100 R: 0\n",
      "episode: 6200 R: 0\n",
      "episode: 6300 R: 0\n",
      "episode: 6400 R: 0\n",
      "episode: 6500 R: 0.9925619834710744\n",
      "episode: 6600 R: 0.9732231404958678\n",
      "episode: 6700 R: 0\n",
      "episode: 6800 R: 0\n",
      "episode: 6900 R: 0\n",
      "episode: 7000 R: 0\n",
      "statistics: [('average_value', 0.4723143), ('average_entropy', 0.9891154), ('average_value_loss', 0.12308089308440685), ('average_policy_loss', -0.014931535683572292), ('n_updates', 16320), ('explained_variance', 0.013151938158646348)]\n",
      "episode: 7100 R: 0.9955371900826446\n",
      "episode: 7200 R: 0.9776859504132231\n",
      "episode: 7300 R: 0.9955371900826446\n",
      "episode: 7400 R: 0.9836363636363636\n",
      "episode: 7500 R: 0.9851239669421488\n",
      "episode: 7600 R: 0.9910743801652893\n",
      "episode: 7700 R: 0\n",
      "episode: 7800 R: 0\n",
      "episode: 7900 R: 0\n",
      "episode: 8000 R: 0.9910743801652893\n",
      "statistics: [('average_value', 0.49544683), ('average_entropy', 0.8569444), ('average_value_loss', 0.14375214509665965), ('average_policy_loss', -0.00813496601767838), ('n_updates', 17920), ('explained_variance', -0.02349333827436695)]\n",
      "episode: 8100 R: 0.9806611570247934\n",
      "episode: 8200 R: 0.9910743801652893\n",
      "episode: 8300 R: 0.9940495867768595\n",
      "episode: 8400 R: 0\n",
      "episode: 8500 R: 0\n",
      "episode: 8600 R: 0\n",
      "episode: 8700 R: 0.9940495867768595\n",
      "episode: 8800 R: 0\n",
      "episode: 8900 R: 0\n",
      "episode: 9000 R: 0\n",
      "statistics: [('average_value', 0.40961626), ('average_entropy', 0.7702982), ('average_value_loss', 0.15000900521874427), ('average_policy_loss', -0.009850711822509765), ('n_updates', 19200), ('explained_variance', -0.008224034270016167)]\n",
      "episode: 9100 R: 0.988099173553719\n",
      "episode: 9200 R: 0.9940495867768595\n",
      "episode: 9300 R: 0.9895867768595041\n",
      "episode: 9400 R: 0.9657851239669422\n",
      "episode: 9500 R: 0\n",
      "episode: 9600 R: 0.976198347107438\n",
      "episode: 9700 R: 0\n",
      "episode: 9800 R: 0.9925619834710744\n",
      "episode: 9900 R: 0.9866115702479339\n",
      "episode: 10000 R: 0\n",
      "statistics: [('average_value', 0.45838696), ('average_entropy', 0.99407583), ('average_value_loss', 0.14613383889198303), ('average_policy_loss', -0.015101687312126159), ('n_updates', 20480), ('explained_variance', -0.0020024653987338326)]\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 10000\n",
    "max_episode_len = 200\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs.flatten()\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while True:\n",
    "        # Uncomment to watch the behavior in a GUI window\n",
    "        # env.render()\n",
    "        action = agent.act(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        obs = obs.flatten()\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = t == max_episode_len\n",
    "        agent.observe(obs, reward, done, reset)\n",
    "        if done or reset:\n",
    "            break\n",
    "    if i % 100 == 0:\n",
    "        print('episode:', i, 'R:', R)\n",
    "    if i % 1000 == 0:\n",
    "        print('statistics:', agent.get_statistics())\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8713d",
   "metadata": {},
   "source": [
    "Test normal agent (no exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca898f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation episode: 0 R: 0.9583471074380165\n",
      "evaluation episode: 1 R: 0\n",
      "evaluation episode: 2 R: 0.9851239669421488\n",
      "evaluation episode: 3 R: 0.9866115702479339\n",
      "evaluation episode: 4 R: 0\n",
      "evaluation episode: 5 R: 0.9866115702479339\n",
      "evaluation episode: 6 R: 0\n",
      "evaluation episode: 7 R: 0.9702479338842975\n",
      "evaluation episode: 8 R: 0.9895867768595041\n",
      "evaluation episode: 9 R: 0\n"
     ]
    }
   ],
   "source": [
    "with agent.eval_mode():\n",
    "    for i in range(10):\n",
    "        obs = env.reset()\n",
    "        obs = obs.flatten()\n",
    "        R = 0\n",
    "        t = 0\n",
    "        while True:\n",
    "            # Uncomment to watch the behavior in a GUI window\n",
    "            # env.render()\n",
    "            action = agent.act(obs)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            obs = obs.flatten()\n",
    "            R += r\n",
    "            t += 1\n",
    "            reset = t == 200\n",
    "            agent.observe(obs, r, done, reset)\n",
    "            if done or reset:\n",
    "                break\n",
    "        print('evaluation episode:', i, 'R:', R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6504efe",
   "metadata": {},
   "source": [
    "Train agent with recurrent policy-value network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2afef6d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 100 R: 0\n",
      "episode: 200 R: 0\n",
      "episode: 300 R: 0.9598347107438017\n",
      "episode: 400 R: 0\n",
      "episode: 500 R: 0.9419834710743802\n",
      "episode: 600 R: 0\n",
      "episode: 700 R: 0\n",
      "episode: 800 R: 0.9836363636363636\n",
      "episode: 900 R: 0.9702479338842975\n",
      "episode: 1000 R: 0\n",
      "statistics: [('average_value', 0.41937178), ('average_entropy', 1.2866253), ('average_value_loss', 0.030587906455621122), ('average_policy_loss', -0.0954683216754347), ('n_updates', 7040), ('explained_variance', -0.2726438094525101)]\n",
      "episode: 1100 R: 0.9583471074380165\n",
      "episode: 1200 R: 0\n",
      "episode: 1300 R: 0.9940495867768595\n",
      "episode: 1400 R: 0.9494214876033058\n",
      "episode: 1500 R: 0\n",
      "episode: 1600 R: 0\n",
      "episode: 1700 R: 0\n",
      "episode: 1800 R: 0\n",
      "episode: 1900 R: 0\n",
      "episode: 2000 R: 0.9628099173553719\n",
      "statistics: [('average_value', 0.44952422), ('average_entropy', 1.1103649), ('average_value_loss', 0.03230734393233434), ('average_policy_loss', -0.08558076874352992), ('n_updates', 12160), ('explained_variance', 0.01298658143137088)]\n",
      "episode: 2100 R: 0\n",
      "episode: 2200 R: 0.9821487603305785\n",
      "episode: 2300 R: 0\n",
      "episode: 2400 R: 0.855702479338843\n",
      "episode: 2500 R: 0.9687603305785124\n",
      "episode: 2600 R: 0.9851239669421488\n",
      "episode: 2700 R: 0\n",
      "episode: 2800 R: 0.9821487603305785\n",
      "episode: 2900 R: 0\n",
      "episode: 3000 R: 0.9717355371900827\n",
      "statistics: [('average_value', 0.3531426), ('average_entropy', 0.9440408), ('average_value_loss', 0.04275246824836358), ('average_policy_loss', -0.07962296106852591), ('n_updates', 16960), ('explained_variance', -0.08111022230974907)]\n",
      "episode: 3100 R: 0.9672727272727273\n",
      "episode: 3200 R: 0.9553719008264463\n",
      "episode: 3300 R: 0\n",
      "episode: 3400 R: 0.9553719008264463\n",
      "episode: 3500 R: 0.9717355371900827\n",
      "episode: 3600 R: 0\n",
      "episode: 3700 R: 0\n",
      "episode: 3800 R: 0.9345454545454546\n",
      "episode: 3900 R: 0\n",
      "episode: 4000 R: 0\n",
      "statistics: [('average_value', 0.41683728), ('average_entropy', 0.8700343), ('average_value_loss', 0.04557751629501581), ('average_policy_loss', -0.07740042331628501), ('n_updates', 22080), ('explained_variance', -0.11934242293395725)]\n",
      "episode: 4100 R: 0\n",
      "episode: 4200 R: 0.9494214876033058\n",
      "episode: 4300 R: 0.9613223140495868\n",
      "episode: 4400 R: 0.8973553719008265\n",
      "episode: 4500 R: 0.9360330578512397\n",
      "episode: 4600 R: 0\n",
      "episode: 4700 R: 0\n",
      "episode: 4800 R: 0\n",
      "episode: 4900 R: 0.9538842975206612\n",
      "episode: 5000 R: 0.9375206611570248\n",
      "statistics: [('average_value', 0.45042613), ('average_entropy', 0.87156725), ('average_value_loss', 0.05322062088176608), ('average_policy_loss', -0.07746655466035009), ('n_updates', 26560), ('explained_variance', -0.12514129097269766)]\n",
      "episode: 5100 R: 0\n",
      "episode: 5200 R: 0\n",
      "episode: 5300 R: 0.9687603305785124\n",
      "episode: 5400 R: 0\n",
      "episode: 5500 R: 0.976198347107438\n",
      "episode: 5600 R: 0.9390082644628099\n",
      "episode: 5700 R: 0\n",
      "episode: 5800 R: 0.9776859504132231\n",
      "episode: 5900 R: 0.9791735537190083\n",
      "episode: 6000 R: 0.9404958677685951\n",
      "statistics: [('average_value', 0.3794452), ('average_entropy', 0.89719737), ('average_value_loss', 0.022109763415064664), ('average_policy_loss', -0.0842820452246815), ('n_updates', 32320), ('explained_variance', -0.04035646434731932)]\n",
      "episode: 6100 R: 0\n",
      "episode: 6200 R: 0.9821487603305785\n",
      "episode: 6300 R: 0.9613223140495868\n",
      "episode: 6400 R: 0.9166942148760331\n",
      "episode: 6500 R: 0\n",
      "episode: 6600 R: 0\n",
      "episode: 6700 R: 0.9434710743801653\n",
      "episode: 6800 R: 0\n",
      "episode: 6900 R: 0.9687603305785124\n",
      "episode: 7000 R: 0\n",
      "statistics: [('average_value', 0.4510181), ('average_entropy', 0.88090235), ('average_value_loss', 0.047280305395834145), ('average_policy_loss', -0.07672018570825458), ('n_updates', 38080), ('explained_variance', -0.05418449218556787)]\n",
      "episode: 7100 R: 0\n",
      "episode: 7200 R: 0\n",
      "episode: 7300 R: 0.9419834710743802\n",
      "episode: 7400 R: 0.9196694214876033\n",
      "episode: 7500 R: 0\n",
      "episode: 7600 R: 0\n",
      "episode: 7700 R: 0.9598347107438017\n",
      "episode: 7800 R: 0.9776859504132231\n",
      "episode: 7900 R: 0.9375206611570248\n",
      "episode: 8000 R: 0\n",
      "statistics: [('average_value', 0.4343819), ('average_entropy', 0.90800357), ('average_value_loss', 0.047342480039224026), ('average_policy_loss', -0.10594706915318966), ('n_updates', 42560), ('explained_variance', -0.09849007112321773)]\n",
      "episode: 8100 R: 0.9687603305785124\n",
      "episode: 8200 R: 0.952396694214876\n",
      "episode: 8300 R: 0\n",
      "episode: 8400 R: 0\n",
      "episode: 8500 R: 0.9791735537190083\n",
      "episode: 8600 R: 0.9836363636363636\n",
      "episode: 8700 R: 0\n",
      "episode: 8800 R: 0\n",
      "episode: 8900 R: 0.976198347107438\n",
      "episode: 9000 R: 0\n",
      "statistics: [('average_value', 0.42734838), ('average_entropy', 0.93604445), ('average_value_loss', 0.04375791155267507), ('average_policy_loss', -0.09980657028034329), ('n_updates', 47360), ('explained_variance', 0.028355120525037414)]\n",
      "episode: 9100 R: 0\n",
      "episode: 9200 R: 0.9538842975206612\n",
      "episode: 9300 R: 0\n",
      "episode: 9400 R: 0\n",
      "episode: 9500 R: 0.9390082644628099\n",
      "episode: 9600 R: 0\n",
      "episode: 9700 R: 0.9776859504132231\n",
      "episode: 9800 R: 0\n",
      "episode: 9900 R: 0.9866115702479339\n",
      "episode: 10000 R: 0\n",
      "statistics: [('average_value', 0.41919503), ('average_entropy', 0.95943063), ('average_value_loss', 0.06350314017385245), ('average_policy_loss', -0.09001651998609304), ('n_updates', 51520), ('explained_variance', -0.11036562510734038)]\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 10000\n",
    "max_episode_len = 200\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    obs = obs.flatten()\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while True:\n",
    "        # Uncomment to watch the behavior in a GUI window\n",
    "        # env.render()\n",
    "        action = agent_rec.act(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        obs = obs.flatten()\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = t == max_episode_len\n",
    "        agent_rec.observe(obs, reward, done, reset)\n",
    "        if done or reset:\n",
    "            break\n",
    "    if i % 100 == 0:\n",
    "        print('episode:', i, 'R:', R)\n",
    "    if i % 1000 == 0:\n",
    "        print('statistics:', agent_rec.get_statistics())\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2c011",
   "metadata": {},
   "source": [
    "Test recurrent PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10cbadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation episode: 0 R: 0.9598347107438017\n",
      "evaluation episode: 1 R: 0\n",
      "evaluation episode: 2 R: 0.9821487603305785\n",
      "evaluation episode: 3 R: 0.9747107438016529\n",
      "evaluation episode: 4 R: 0\n",
      "evaluation episode: 5 R: 0\n",
      "evaluation episode: 6 R: 0.903305785123967\n",
      "evaluation episode: 7 R: 0.988099173553719\n",
      "evaluation episode: 8 R: 0\n",
      "evaluation episode: 9 R: 0\n"
     ]
    }
   ],
   "source": [
    "with agent_rec.eval_mode():\n",
    "    for i in range(10):\n",
    "        obs = env.reset()\n",
    "        obs = obs.flatten()\n",
    "        R = 0\n",
    "        t = 0\n",
    "        while True:\n",
    "            # Uncomment to watch the behavior in a GUI window\n",
    "            # env.render()\n",
    "            action = agent_rec.act(obs)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            obs = obs.flatten()\n",
    "            R += r\n",
    "            t += 1\n",
    "            reset = t == 200\n",
    "            agent_rec.observe(obs, r, done, reset)\n",
    "            if done or reset:\n",
    "                break\n",
    "        print('evaluation episode:', i, 'R:', R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8fed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
